{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Batch vs Mini-batch vs stochastic gradient descent"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the previous sections, neural networks models were trained on the entire training set containing m examples. This means that, in order to compte the cost function and update the model parameters, a complete pass, called *epoch* over all the $m$ training examples is inevitable. This may be extremely time consuming in this deep learning regime where the size of the training set is huge."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "This motivates the idea to run the gradient descent on a subset of the $m$ training examples and update the parameters. These subsets are refered to as batches and the gradient descent is referred to as **mini-batch gradient descent**. It usually run faster than the gradient descent with all training examples, $m$.\n",
    "\n",
    "In the case where the batches are of size 1, the gradient descent is called a **stochastic gradient descent**.\n",
    "\n",
    "In the case where the batch size is $m$, the gradient descent algorithm is just a **batch gradient descent**."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## The implementation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Below is a pseudo-code implementation for the gradient descent with $T$ batches"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "```\n",
    "repeat for t=1 to t=T:\n",
    "  get the batch x_t\n",
    "  calculate forward propagation with x_t\n",
    "  compte cost for batch t\n",
    "  apply back propagation\n",
    "  update weights\n",
    "```"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "When training batch vs mini-batch gradient descent, the cost function tends to descent smoothly in the case of batch gradient descent. However, in the case of mini-batch gradient descent, the general trend of the cost graph will go down as the number of iteration increases however the graph is oscillating on contrast to smooth behavior on the batch gradient descent. Generally, as the mini-batch size $t$ is closer to 1, the graph oscillation increases. In the extreme case of stochastic gradient descent, the algorithm may not reach to the global optimum due to the noisy oscillation it makes while descending. Consider the following image, taken from AndrewNg course, describing such situation."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "![batch vs minibatch gradient descent](images/batch_vs_minibatch_vs_stochastic.png)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The image is a plot for the contours of the gradient descent while going down to the global minimum. The magenta oscillating graph represent the case of stochastic gradient descent while the blue smooth almost linear graph represents the batch gradient descent training. The green graph represents the case of mini-batch gradient descent with reasonable batch size $t$. However, reaching the global minimum is, also, not guaranteed."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## General guidelines on choosing the mini-batch size $t$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- If the training set is small, the batch gradient descent is the best candidate.\n",
    "- If the training set is quite large, the batch size can be in between [64,512]\n",
    "- Generally, setting $t$ to be a power of 2 performs better.\n",
    "- Make sure the training mini-batch fits on the GPU/CPU memory."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Exponentially weighted average"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "exponentially weighted average is a statistical tool to estimate the average of variable values from its history. For example, to estimate the average of day's temperature based on the previous days temperatures history."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The general formula of exponentially weighted average, sometimes called moving average, is:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "$$V_{t} = \\beta V_{t-1} + (1-\\beta)\\theta_{t}$$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Couple of notes on the parameter $\\beta$:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- $\\beta \\in [0,1]$\n",
    "- controls how the history affects the moving average. As long as $\\beta$ increases, we are given more weights to the previous history. In particular, the number of values taken from the history is approximately $\\frac{1}{1-\\beta}$.\n",
    "- for small values of $\\beta$, the moving average becomes more susceptible to outliers. \n",
    "- The graph for small values or $\\beta$ is more noisy and becomes smoother as $\\beta$ increases."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Bias correction"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the initial run of the moving average, it may not give the best estimate as $V_0=0$. However, setting $V_t = \\frac{V_t}{1-\\beta^2}$ gives better approximation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Gradient Descent with Momentum"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The idea behind momentum is to reduce the oscillations/noise resulting, for example,  from mini-batch algorithms.The idea is to average the gradients on each batch updates. The average algorithm used is the moving average discussed in the previous section."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## The implementation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "on iteration t:\n",
    "```\n",
    "compute dw,db\n",
    "Vdw = BVdw + (1-B)dw\n",
    "Vdb = BVdb + (1-B)db\n",
    "update w = w-alpha Vdw\n",
    "update b = b- alpha Vdb\n",
    "```"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# RMSProp"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "RMSProb stands for Root Mean Square prob. This is another optimization to the gradient descent algorithm that tries to address the problem of noisy oscillation of the gradient descent while trying to climbing down towards the global minimum."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## How it works?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "on iteration t:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "```\n",
    "compute dw,db on the current mini-batch\n",
    "Sdw = B*Sdw + (1-B) dw2\n",
    "Sdb = B*Sdb + (1-B) db2\n",
    "w := w= a*(dw/sqrt{Sdw})\n",
    "b := b= a*(db/sqrt{Sdb})\n",
    "```"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Notice that the main difference between the RMSProb and the momentum is that in the RMSProb formula, the derivatives are divided by the square root of the weighted average unlike the momentum where the parameters are just subtracted from their weighted average."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We hope that db is relatively large, as it is only one dimensional vector while dw is relatively small as it is high dimensional vector. Hence, the oscillations on the b dimensions got more smaller and smoother. The net effect of that the updates moves faster and smoother with a larger learning rate $\\alpha$. In practice, the oscillations might be on the direction with not only db but many other parameters from dw. But the concept remains the same"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Adam algorithm"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Adam optimization algorithm is nothing but a combination of RMSProb and Momentum. It stands for *ADAptive Moment estimation* Here is how it works."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "```\n",
    "Vdw=0, Sdw=0, Vdb=0, Sdb=0\n",
    "on iteration t:\n",
    "  compute dw,db using current mini-batch\n",
    "  Vdw = B1*Vdw + (1-B1)dw, Vdb = B1*Vdb + (1-B1)db\n",
    "  Sdw = B2*Sdw + (1-B2)dw^2, Sdb=B2*Sdb + (1-B2)db^2\n",
    "  Vdw[corrected] = Vdw/(1-B1^t), Vdb[corrected] = Vdb/(1-B1^t)\n",
    "  Sdw[corrected] = Sdw/(1-B1^t), Sdb[corrected] = Sdb/(1-B1^t)\n",
    "  w = w-alpha*(Vdw[corrected]/(sqrt{Sdw[corrected]}+epsilon)), b=b-alpha*(Vdb[corrected]/(sqrt{Sdb[corrected]}+epsilon))\n",
    "```"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## common choices for the hyperparameters"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- $\\alpha$:needs to be tuned \n",
    "- $\\beta_1$:0.9\n",
    "- $\\beta_2$:0.999\n",
    "- $\\epsilon:10^{-8}$"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
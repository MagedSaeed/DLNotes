{
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# Binary Classification Problem"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "This problem is, for a given image, indicate whether the image has a cat or not. It is the practical problem that will be used through out the course to practice building the neural network."
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "The image will be represented as a three separate matrices. Each matrix represent one channel of red, green, and blue colors. These matrices will be refered as the set of features, X. Y, on the other hand, is a vector for each image indicating whether the image contains a cat or not."
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "In order to transform image matrices to an input vector, they need to be unrolled to a vector of length 64\\*64\\*3=12288 as each image is an 64 pexil image."
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "The problem is formulated as $$F(X) \\longrightarrow y$$ where $F(X)$ is the function to be learned by the neural network, $X$ is the matrix of feature vectors, and $Y$ is the vector of outputs for each feature vector."
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Notations"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "- $M$ represent an example ($x^{(i)}$,$y^{(i)}$).\n",
                "\n",
                "- $M_{train}$ represent training examples. Similarly, $M_{test}$, and $M_{dev}$ represents testing and development examples respecitvely. Let $m$ represents the number of training examples in $M$.\n",
                "\n",
                "- $X$ represents the matrix of $x^{i}$ vectors as follows: \n",
                "\n",
                "$$\\begin{bmatrix} . & . & . & .\\\\ . & . & . & . \\\\ x^{(1)} & x^{(2)} & .. & x^{(m)} \\\\ . & . & . & .\\\\ . & . & . & . \\end{bmatrix}$$\n",
                "\n",
                "In that since, $X$ is of size $n_x\\times m$ where $n_x$ is the length of any $x^{i}$ vector, 12288 in this problem, and $m$ is the size of the examples set $M$. More formally: $X \\in \\mathbb{R}^{(n_x , m)}$\n",
                "\n",
                "- $Y$ is the set of outputs. It is, as $X$, is stacked vertically as follows:\n",
                "\n",
                "$$\\begin{bmatrix} y^{(1)} & y^{(2)} & .. & y^{(m)} \\end{bmatrix}$$\n",
                "\n",
                "In this regard, $Y$ will be defined more formally as: $Y \\in \\mathbb{R}^{(1 , m)}$\n"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Logestic Regression"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "given an input feature x, a vector of an image, the requirement is to predict a propability score $$\\hat{y} = P(y=1|x)$$ that the image contains a cat."
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "The parameters of the model are the weights, $w$ and the bias $b$."
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "The formulat can be derived from the linear regression conjugated with sigmod function $$\\hat{y} = \\sigma(w^Tx + b)$$ where $$\\sigma(z) = \\frac{1}{1+e^{-z}}$$"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "### Some notes about $\\sigma (z)$ function"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "- If the value $z$ is very large, then the value of the $\\sigma$ becomes very close to 1.\n",
                "- If the value of $z$ is very small, like a very large negative number, then the value of $\\sigma$ function becomes very small."
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Logestic Regression Training"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "### The loss function derivation"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "The linear regression loss (error) function $$L(\\hat{y},y) = \\frac{1}{2}(\\hat{y}-y)^2$$ is not applicable here as it is not convex. i.e. the gradient descent algorithm is not guarnteed to find a global minimum for the function. The function is not convex due to the use of the sigmoid $\\sigma(z)$ function."
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "The following Loss function is used in logestic regression $$ L(\\hat{y},y) = - (y\\log{\\hat{y}} + (1-y)\\log{(1-\\hat{y})}) $$"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "Some intuition why this loss function works:\n",
                "\n",
                "- If $y=1$, then, in order to minimize the function $\\hat{y}$ should be as large as possible. The second term is zero.\n",
                "- If $\\hat{y}=1$, then, $(1-\\hat{y})$ should be as large as possible, hense $\\hat{y}$ should be as small as possible.\n",
                "\n",
                "Hense, if the true value $y$ is 1, then $\\hat{y}$ is pushed to be as large as possible i.e. closer to 1. Also, if $y = 0$, then $\\hat{y}$ is pushed to be as small as possible, i.e. closer to zero."
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "### The Cost function derivation"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "$$J(w,b) = \\frac{1}{m} \\sum^m_{i=1}L(\\hat{y}^{(i)},y^{(i)})$$ \n",
                "\n",
                "where L is the loss function derived in the previous subsection. Hence, the final formula would be:\n",
                "\n",
                "$$J(w,b) = -\\frac{1}{m}\\sum^{m}_{i=1}(y^{(i)}\\log(\\hat{y}^{(i)})+(1-y^{(i)})\\log(1-\\hat{y}^{(i)}))$$"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Gradient Descent"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "The key part of the gradient descent algorithm is iteratively updates the weights and biases until some threshold or predefined number of iterations. The formula is $$w := w- \\alpha \\frac{\\partial J(w,b)}{\\partial w} $$ $$ b := b-\\alpha \\frac{\\partial J(w,b)}{\\partial b} $$\n",
                "\n",
                "where:\n",
                "- $\\frac{\\partial J(w,b)}{\\partial w}$ is the partial derivative of the cost function with respect to weights parameter, w. Similarly, $\\frac{\\partial J(w,b)}{\\partial b}$ is the bias partial derivative.\n",
                "-  $\\alpha$ is a parameter used to control the update rate. It is usually called, the learning rate.\n",
                "\n"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# The Computation Graph"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "The computation graph organizes the computation of the gradient descent and its derivatives on both passes, forward pass and backward pass. Consider the following function $$f(x)=3(a+bc)$$ We can organize it as the following computation graph:"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "<figure class=\"image\">\n",
                "    <center><img src=\"imgs/computation_graph.png\"/></center>\n",
                "    <center><figcaption> Fig. 1: The Computation Graph </figcaption></center>\n",
                "</figure>"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "the variable $u$ and $v$ are used to facilitate the computation."
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "the derivative of j with respect to v can be calculated as $\\frac{dj}{dv}$ which is 3. The derivative $\\frac{dj}{du}$ can be calculated using the chain rule as $\\frac{dj}{dv} \\times \\frac{dv}{du}$ which is $3 \\times 1 = 3$ and so on until reaching a,b and c variables."
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Logestic Regression Computation Graph"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "Consider the following graph for logestic regression with two features x1,x2 example."
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "<figure class=\"image\">\n",
                "    <center><img src=\"./imgs/logestic_regression_computation_graph.png\" /></center>\n",
                "    <center><figcaption> Fig. 2: The Logestic Regression Computation Graph </figcaption></center>\n",
                "</figure>"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                " ![test](imgs/logestic_regression_computation_graph.png)"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "Note that $\\hat{y}$ is replaced with $a$ in the computation graph just for presentation conveniences. Now, in order to compute the derivative of the loss function $l$ with respect to $a$ we have:\n",
                "\n",
                "$$ \\frac{\\partial l(a,y)}{\\partial a} = -(y\\log{a}+(1-y)(\\log{1-a})) $$\n",
                "\n",
                "$$ - \\frac{y}{a} + \\frac{1-y}{1-a} $$\n",
                "\n",
                "Similarly, to compute the derivative of the loss function with respect to $z$, the chain rule will be used as follows:\n",
                "\n",
                "$$ \\frac{\\partial l(a,y)}{\\partial z} = \\frac{\\partial l(a,y)}{\\partial a} * \\frac{\\partial a}{\\partial z}$$\n",
                "\n",
                "$$ (-\\frac{y}{a}+\\frac{1-y}{1-a}) \\times (a(1-a)) = a-y$$"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "finally, to compute the derivatives for the parameters w,b as follows: \n",
                "\n",
                "$$\\frac{\\partial l}{\\partial w_1} = x_1 \\times(a-y)$$ \n",
                "\n",
                "$$\\frac{\\partial l}{\\partial w_2} = x_2 \\times (a-y)$$\n",
                "\n",
                "$$ \\frac{\\partial l}{\\partial b} = (a-y) $$ \n",
                " \n",
                "where $a-y$ is the value of $\\frac{\\partial l}{\\partial z}$"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "Finally, this one example derivation of the gradient descent algorithm can be generalized for $w_1$ to a dataset of m examples as follows:\n",
                "\n",
                "$$ \\frac{\\partial J(w,b)}{\\partial w_1} = \\frac{1}{m} \\sum^m_{i=1} \\frac{\\partial l(a^{(i)},y^{(i)})}{\\partial w_1} $$\n",
                "\n",
                "The rest of the varialbes, $w_2$ and $b$ have similar derivation over m examples."
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Vectorization and Broadcasting"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "Vectorization refers to the process of applying matrix operations with the help of parallalisim in the processor architecture. Usually, it is acheived through special packages like `numpy` for Python. Examples of such operations could be dot product or matrix addition."
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "Broadcasting refers primarly to the process of aplying an operation of a scalar to a vector. For example adding, subtracting or multiplying a scalar by a vector exploying parallelisim features of the processor."
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}